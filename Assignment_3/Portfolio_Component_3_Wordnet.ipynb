{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Portfolio Component 3: WordNet\n",
        "##Wyatt Kirby (IRK180000)\n",
        "###CS 4395.001\n",
        "\n",
        "WordNet was created to prove the theory that people organize concepts in a mental hierarchy. It stores a miriad of words, a short definition, and examples of how the words are used. "
      ],
      "metadata": {
        "id": "TObYm5pePVP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing what is needed\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.book import text4\n",
        "import re\n",
        "import math"
      ],
      "metadata": {
        "id": "QQaJ0W9g0JdP"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Noun"
      ],
      "metadata": {
        "id": "GKiMjOCO920F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YXQ-F4PiPI9H",
        "outputId": "28627ba1-615d-4ed4-bb04-a42bb6c540cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('cake.n.01'),\n",
              " Synset('patty.n.01'),\n",
              " Synset('cake.n.03'),\n",
              " Synset('coat.v.03')]"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ],
      "source": [
        "#Getting all of the synsets for cake\n",
        "wn.synsets('cake')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Getting the definition, examples of use, and lemmas of coat."
      ],
      "metadata": {
        "id": "IttKwvWa4Jx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting information on one of the syset (attic)\n",
        "wn.synset('coat.v.03').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rInNgr2a3BxH",
        "outputId": "4303f585-bfa1-4ff7-b14e-108ae0171877"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'form a coat over'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zfnfWJbG4Iyo",
        "outputId": "8e1ad0fa-91e3-4258-abb8-fc990bd70550"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dirt had coated her face']"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5J8UiZ1X4JG-",
        "outputId": "7e0da114-9b97-4b5a-f26b-49788ea65a1c"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('coat.v.03.coat'), Lemma('coat.v.03.cake')]"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I'm traversing the heirarchy as high as I can go using the synset \"coat\"."
      ],
      "metadata": {
        "id": "qMe77d6I5fud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slather = wn.synset('coat.v.03')\n",
        "up = lambda x: x.hypernyms()\n",
        "list(slather.closure(up))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Bjyn8zQA5pkM",
        "outputId": "33cb86b8-9310-4cab-add5-87ff867c95f7"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('cover.v.02'), Synset('touch.v.05')]"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that for nouns, the higher up they are in the heirarchy, the broader the definition of the word is. We went from a fairly specific definition to a very broad definition the further up the tree we went. When you coat something, you do touch it but it specifies *how* an object is being touched with another."
      ],
      "metadata": {
        "id": "laPHRfxL6gP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Getting the hypernyms, hyponyms, meronyms, holonyms, and antonym of coat."
      ],
      "metadata": {
        "id": "VX4Pcce77Yw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cjkQgkjh7jXC",
        "outputId": "cd23aea2-8719-4e26-d200-430e6b5c611d"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('cover.v.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vKTNhUAL7umG",
        "outputId": "2a5cd01a-222b-432c-fa51-9d4976853312"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').part_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cPiGUZiS71Hx",
        "outputId": "442cb5a4-03cb-4421-ba99-8bc0600dd186"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').part_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ufj2ULX-78U2",
        "outputId": "f0a31d1f-e0fd-4000-adb7-9982e32bc149"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('coat.v.03').lemmas()[0].antonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uLmVYt2p8Adu",
        "outputId": "e68e097b-b88f-4252-9c5d-f12a6280970f"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the noun I picked was a little boring :("
      ],
      "metadata": {
        "id": "X4LShRii8k9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Verb"
      ],
      "metadata": {
        "id": "weJeh9Ta9qBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting all the sysnets for confuse\n",
        "wn.synsets('confuse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EL7ZaucZ9drJ",
        "outputId": "a55d73ae-5bb2-4a7d-fbdb-e5a3d7b91ea5"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('confuse.v.01'),\n",
              " Synset('confuse.v.02'),\n",
              " Synset('confuse.v.03'),\n",
              " Synset('jumble.v.02'),\n",
              " Synset('confuse.v.05')]"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Getting the definition, examples of use, and lemmas of jumble."
      ],
      "metadata": {
        "id": "5SYUdueI-cDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('jumble.v.02').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YlaSc2tj-lAr",
        "outputId": "a1b43e40-52a1-484c-b8cc-5ffadc77e828"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'assemble without order or sense'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('jumble.v.02').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ShTWf9Xs-qqo",
        "outputId": "b393e738-ec59-4380-b1fe-8dddbde11f52"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['She jumbles the words when she is supposed to write a sentence']"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('jumble.v.02').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "orqoKiiS-tp9",
        "outputId": "8bf4d65d-2361-4c03-afdd-fc04859ad2e0"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('jumble.v.02.jumble'),\n",
              " Lemma('jumble.v.02.confuse'),\n",
              " Lemma('jumble.v.02.mix_up')]"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I'm traversing the heirarchy as high as I can go using jumble."
      ],
      "metadata": {
        "id": "asEp3t9o-0Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baffle = wn.synset('jumble.v.02')\n",
        "up = lambda x: x.hypernyms()\n",
        "list(baffle.closure(up))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aWQaGWpz_FPo",
        "outputId": "184f6a24-07f5-4a0e-b973-2b3fdc2c6edd"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('assemble.v.01'),\n",
              " Synset('join.v.02'),\n",
              " Synset('make.v.03'),\n",
              " Synset('connect.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like it performed similarly to how traversing up their hierarchy did for nouns. The words given keep becoming more and more generalized the higher up the tree we get."
      ],
      "metadata": {
        "id": "STupZRsK_tri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Morphy"
      ],
      "metadata": {
        "id": "2RjbSzSTB5SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('confused', wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qAYew_29_VRG",
        "outputId": "c40e4f92-6e9c-4ee9-ff2c-09c77c934dcd"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'confuse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('confusing', wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xnA60EmdCNGY",
        "outputId": "0b5089c1-01fd-4c4a-b015-1d020013e46f"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'confuse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('confuses', wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0Dl-kXOCCQi1",
        "outputId": "78a047a0-2cc1-4417-d88c-46bcd6c46a79"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'confuse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Two Similar Words"
      ],
      "metadata": {
        "id": "bgd99Hv7ClM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my two words I chose bare and bear as they sound similarly but have different meaning. I'm thinking that the similarity will be low."
      ],
      "metadata": {
        "id": "R12NTMtwC63k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bare = wn.synset('bare.v.01')\n",
        "bear = wn.synset('bear.n.01')\n",
        "print(bare.path_similarity(bear))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EWqy__XLCpub",
        "outputId": "c9c376c3-2688-433c-e271-8c2d9e7857a8"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for Wu-Palmer"
      ],
      "metadata": {
        "id": "Ptv5XLnYET9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.wup_similarity(bare,bear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F8C5gZe3D6KE",
        "outputId": "5a7e1b0e-8b9f-48f5-ea4b-8cd685a36218"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11764705882352941"
            ]
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lusk Algorithm time"
      ],
      "metadata": {
        "id": "9X63QEC-EZYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = ['I', 'have', 'seen', 'a', 'bear', 'in ', 'the', 'yard','!']\n",
        "s2 = ['Sharol', 'try', 'and', 'bare', 'with', 'it', '.']\n",
        "s3 = ['Jeff', 'has', 'bare', 'arms', '.']\n",
        "s4 = ['Sharol', 'has', 'bear', 'arms', '.']\n",
        "print(lesk(s1, 'bear'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JlOqHxeIESQC",
        "outputId": "4a32016e-edce-446e-b3c3-bf72be7fb337"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('wear.v.02')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(s2, 'bare'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DgjBtlYdGGTn",
        "outputId": "f5d019fe-7922-48cc-ca7e-e6d42d2bbe6d"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('denude.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(s3, 'bare'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t0gquodcGMzn",
        "outputId": "091681a3-6969-4520-ce90-10d246f57431"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('denude.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(s4, 'bear'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c8MgtWNoGVSR",
        "outputId": "3cdfa6a6-6f6e-4356-c1bc-90ed54f6c54f"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('yield.v.10')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think the words I picked weren't the best suited for this algorithm so I'm going to try again with another set of words."
      ],
      "metadata": {
        "id": "ljtTBKahGZzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = ['I', 'burned', 'my', 'toast', '.']\n",
        "s2 = ['John', 'saw', 'the', 'stars', 'last', 'night', '.']\n",
        "print(lesk(s1, 'burned'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B0QpgQpCGiwf",
        "outputId": "3c9753a2-ff6b-4eaa-fa74-1f8f6625e258"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('sunburn.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesk(s2, 'stars'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "udnEbsWBHG0U",
        "outputId": "9d963ce7-70f3-4266-c3c6-38e41bed6af5"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('star.n.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('star.n.03').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "51qPjX10HLE3",
        "outputId": "02b287dd-07c4-47e4-e805-9dc69d012582"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'any celestial body visible (as a point of light) from the Earth at night'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I got slightly better outputs, but I wonder why it picked the words it picked."
      ],
      "metadata": {
        "id": "_Zf7Y_B7HSoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('bare.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B6g6uFC4HauJ",
        "outputId": "34622c55-40b7-4ff3-c160-96827436fc15"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lay bare'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('denude.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ECVYSh0nHmB4",
        "outputId": "f289630b-b12e-4416-ca8a-702ad74df50c"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lay bare'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('bear.n.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EWHBxmuwHrbp",
        "outputId": "629159bc-f2e3-4bb6-c9c4-4347ab18f6a2"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'massive plantigrade carnivorous or omnivorous mammals with long shaggy coats and strong claws'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('wear.v.02').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cl81q2_IHw-n",
        "outputId": "313333e5-17bf-496b-be35-197aaea1b520"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"have on one's person\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('yield.v.10').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gf13COwJH-39",
        "outputId": "000cb0b5-58bb-457e-82df-96cb36185d2d"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bring in'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('burn.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2qLvKx6fIclz",
        "outputId": "c3570591-e00e-4674-f46f-768971ebfc48"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'destroy by fire'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('sunburn.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j2-m842DIXRM",
        "outputId": "1e0a9988-7189-45ba-df81-f8f0709d66d9"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get a sunburn by overexposure to the sun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like when it tries the best it can to find words with similar meanings. The sentences I used were tricky for the algorithm, but it managed to find a couple synonyms for some of the words or just words that are related were chosen. Still very impressive."
      ],
      "metadata": {
        "id": "pLWTduQ5IDVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SentiWordNet"
      ],
      "metadata": {
        "id": "Js921YycJhv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet functions similarly to WordNet, but gives words scores based on how positive, negative, or objective the word is. This could be used to sift through articles to see if they are objective or use emotional language and show bias in the article (could help spot propoganda or fake news). It could also be used for teaching people languages, ensuring that people aren't accidentally using words that have the undesirable connotations in the language."
      ],
      "metadata": {
        "id": "yCnijlilJoXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sents(s):\n",
        "    tokens = s.split()\n",
        "    for t in tokens:\n",
        "      slist = list(swn.senti_synsets(t))\n",
        "      if slist:\n",
        "        print(t)\n",
        "        print(\"Positive Score: \", slist[0].pos_score())\n",
        "        print(\"Negative Score: \", slist[0].neg_score())\n",
        "        print(\"Objective Score: \", slist[0].obj_score())"
      ],
      "metadata": {
        "id": "hS1gsHgVO0aw"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents('awful')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a0X-9MljN-lX",
        "outputId": "d4a524b6-edf0-4739-8c64-ffef74de0d9c"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "awful\n",
            "Positive Score:  0.0\n",
            "Negative Score:  0.875\n",
            "Objective Score:  0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"I loved that movie\"\n",
        "sents(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s9DtqpFkMvkM",
        "outputId": "81bffa2b-269a-4696-b13a-b6c378bea822"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "Positive Score:  0.0\n",
            "Negative Score:  0.0\n",
            "Objective Score:  1.0\n",
            "loved\n",
            "Positive Score:  0.5\n",
            "Negative Score:  0.0\n",
            "Objective Score:  0.5\n",
            "movie\n",
            "Positive Score:  0.0\n",
            "Negative Score:  0.0\n",
            "Objective Score:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like SentiWordNet is fairly good at catagorizing words as long as it has the exact definition that an individual wants to use. For 'awful' it seems to have used version 1 of the definition of awful instead of the second definition (which had a score of 62.5% negative). This would be very useful so that a chat bot can distinguish what a person is asking for or needs from a given interaction. If a user seems to be using a lot of negative words, the chatbot could alter its word choice to better suit the users mental state. It could be used to make sure that a given sentence makes sense and isn't giving mixed messages before sending to a user."
      ],
      "metadata": {
        "id": "PzvjhzoRSi26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Collocation"
      ],
      "metadata": {
        "id": "9WeM-BNBT21W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocation is when two words come together to create a specific meaning. This means that a synonyms of the words couldn't be substituted for one of the words (or both) and still have the same meaning. Examples of this include \"big sister\" as big couldn't be substituted for large and have the same meaning.  "
      ],
      "metadata": {
        "id": "TMN_6IQHT5Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " text4.collocations()\n",
        " sText4 = ' '.join(text4.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fV3oZkiLUw-v",
        "outputId": "7a421d2a-2c23-4cfa-9d20-8896edb4c518"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prob(word):\n",
        "  nums = text4.count(word)\n",
        "  num = nums/149797\n",
        "  return num"
      ],
      "metadata": {
        "id": "7-frGeg-WqAu"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob1(word):\n",
        "  #I used the text$ that had been joined together into a string because its simpler to find a phrase in a string than it is in a list where each\n",
        "  #word is seperated\n",
        "  nums = sText4.count(word)\n",
        "  num = nums/149796\n",
        "  return num"
      ],
      "metadata": {
        "id": "oy14KZbYek4T"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wordLink(phrase):\n",
        "  words = phrase.split()\n",
        "  num = (prob1(phrase)) / ((prob(words[0]) * prob(words[1])))\n",
        "  num = math.log(num, 2)\n",
        "  return num"
      ],
      "metadata": {
        "id": "Lq5W9-YhYFac"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the examples from the textbook so I can verify the PMI"
      ],
      "metadata": {
        "id": "IMcZLONKgYsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PMI is: \", wordLink('fellow citizens'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2-xYey_UZIQX",
        "outputId": "ecd1a691-730c-4160-ee1f-ab94a89c9cf5"
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PMI is:  8.144417647428305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PMI is: \", wordLink('the citizens'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ptU2To6bcWUJ",
        "outputId": "4cec3d28-c2d0-4c91-defd-9df9b9e7cd77"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PMI is:  -0.4828390389043306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My methods seem to be working as they produced the same numbers that were present in the text book. For the first one, it shows that there is a highlikelihood that 'fellow citizens' is a collocation as the probability of them appearing together as opposed to the probability of them appearing seperately shows that they are *very* likely to be used together. The opposite is true for 'the citizens', as the -.48 suggests that the words were more likely to appear seperately than together in the text.\n",
        "\n",
        "Other examples:"
      ],
      "metadata": {
        "id": "-e7MVyixgeq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PMI is: \", wordLink('Chief Magistrate'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3oYK9IbNgg0v",
        "outputId": "ce6ba902-df1b-4513-e29e-ac5881047c1d"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PMI is:  12.247800390745615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PMI is: \", wordLink('years ago'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yWQMKTG9goEr",
        "outputId": "063d3baf-f288-491b-a9a2-26cd61992424"
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PMI is:  9.328243383300935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Chief Magistrate\" seems to be a collocation as the PMI is *very* high. This means that the two words are far more likely to be used together, meaning its likely that those two words together have a specific meaning. \n",
        "Oddly enough, 'years ago' has a high PMI score despite not being a true collocation. You could substitute ago with before and get the same meaning, but it is still more common to say years ago as opposed to years before. This would cause the PMI to be high despite not being a true collocation."
      ],
      "metadata": {
        "id": "brWsipbThQ7W"
      }
    }
  ]
}